{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeperfont\n",
    "*[Website](http://nbviewer.jupyter.org/github/terryspitz/ipython_notebooks/blob/master/deeperfont.ipynb)*\n",
    "\n",
    "Deeperfont is a Neural Network attempt at the 'Font Problem' - that is, how to capture the essence of a font in such a way as to generalise to unseen glyphs and to allow interpolation between different fonts.  This problem was noted as early as 1979 when Donald Knuth wrote the first version of [MetaFont](https://en.wikipedia.org/wiki/Metafont).\n",
    "\n",
    "For this network initial research suggested the use of [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/) as best practise for both getting started and long-term research.  \n",
    "\n",
    "As output the network will generate a set of [glyph outlines](https://en.wikipedia.org/wiki/Glyph).  The encoding of outputs has been considered in a number of ways: \n",
    "* raw (x,y) coordinates, for example as expressed in the [TrueType](https://en.wikipedia.org/wiki/TrueType) font file\n",
    "* incremental coordinate changes (dx,dy)\n",
    "* a conversion of these outlines to (angle, distance) pairs for each line as in [Turtle graphics](https://en.wikipedia.org/wiki/Turtle_graphics) (best known for its  use in [Logo](https://en.wikipedia.org/wiki/Logo_(programming_language).)  We do not currently model the bezier curves used in the original glyphs; a future enhancement could use a rendered glyph as the source of font coordinates to train against.\n",
    "\n",
    "Considering the [loss](https://en.wikipedia.org/wiki/Loss_function) or evaluation function we note that the exact sequence of points in the glyph can be varied while generating identical rendered output, for example a line segment can be split into a number of smaller colinear segments.  The network should be free to express its results in any equivalent way.  The evaluation function is therefore required to compare rendered output.  We build an evaluation function in pure Tensorflow using a [scanline algorithm](https://en.wikipedia.org/wiki/Scanline_rendering) to generate a tensor containing the x coordinates of the outline for a set of equi-spaced y line.  The predicted and true outlines are then compared by calculating the difference in these coordinates (or perhaps *visible pixels* in a future enhancement).\n",
    "\n",
    "We would like access to the trained glyph outlines but since the network loss function requires the x coordinates we use a final lambda layer to render the outlines for comparison in the loss function, then use the previous, outline generation layer from the fitted model when making predictions.\n",
    "\n",
    "As input we provide a [one-hot](https://en.wikipedia.org/wiki/One-hot) vector respresenting the individual glyphs to render.  In a future enhancement where we train against multiple fonts, this input could also include a font feature or even font classifications such as serif/sans-serif/script/etc.\n",
    "\n",
    "See also:\n",
    "* [MetaFont](https://en.wikipedia.org/wiki/Metafont)\n",
    "* [Metaflop - interactive MetaFont](http://www.metaflop.com/modulator)\n",
    "* [deepfont](https://erikbern.com/2016/01/21/analyzing-50k-fonts-using-deep-neural-networks.html)\n",
    "* https://arxiv.org/abs/1507.03196\n",
    "* https://pypi.python.org/pypi/FontTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "1.2.0\n",
      "2.0.6\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageChops, ImageFont\n",
    "from IPython.display import display\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "import keras.initializers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Scheme(Enum):\n",
    "    \"\"\"\n",
    "    Enum defining scheme for respresenting the glyph outlines:\n",
    "    XY: the raw (x,y) coordinates\n",
    "    DXDY: incremental coordinate changes (dx,dy)\n",
    "    ANGDIST: a conversion of these outlines to (angle, distance) pairs for each line \n",
    "    \"\"\"\n",
    "    XY = 1\n",
    "    DXDY = 2\n",
    "    ANGDIST = 3\n",
    "\n",
    "def renderGlyphs(gls, max_points_per_line, ygrid, scheme):\n",
    "    '''\n",
    "    Pure tensorflow function\n",
    "    Input: 2D tensor of glyph * outlines (either x,y or angle, distance pairs)\n",
    "    Output: glyph * matrix of sorted x coords for each line per y coording\n",
    "    '''\n",
    "    if scheme == Scheme.XY:\n",
    "        xs = gls[:,::2]\n",
    "        ys = gls[:,1::2]\n",
    "        visible = tf.logical_or(xs[:,1:]>0,ys[:,1:]>0)\n",
    "    elif scheme == Scheme.DXDY:\n",
    "        dxs = gls[:,::2]\n",
    "        dys = gls[:,1::2]\n",
    "        xs = tf.cumsum(dxs, axis=-1)+1e-2\n",
    "        ys = tf.cumsum(dys, axis=-1)+1e-2\n",
    "        visible = tf.logical_or(xs[:,1:]>0,ys[:,1:]>0)\n",
    "    elif scheme == Scheme.ANGDIST:\n",
    "        angles = gls[:,::2]\n",
    "        dists = gls[:,1::2]\n",
    "        visible = dists[:,1:]>0\n",
    "        #turn angles,dists into coordinates\n",
    "        xs = tf.cumsum(tf.abs(dists)*tf.cos(angles*math.pi), axis=-1)+1e-2\n",
    "        ys = tf.cumsum(tf.abs(dists)*tf.sin(angles*math.pi), axis=-1)+1e-2\n",
    "    #offset to create line start x1,y1 to end x2,y2\n",
    "    x1s = xs[:,:-1]\n",
    "    x2s = xs[:,1:]\n",
    "    y1s = ys[:,:-1]\n",
    "    y2s = ys[:,1:]\n",
    "    #add 3rd dimension (size=1) so following interpolation in y is broadcast across all lines\n",
    "    xx1s=tf.expand_dims(x1s,-1)\n",
    "    xx2s=tf.expand_dims(x2s,-1)\n",
    "    yy1s=tf.expand_dims(y1s,-1)\n",
    "    yy2s=tf.expand_dims(y2s,-1)\n",
    "    #interpolate the x coords for all lines at all y coord\n",
    "    xxs = xx1s + (xx2s-xx1s)*(ygrid-yy1s)/(yy2s-yy1s)\n",
    "    #zero x coords outside of line y bounds or where dy=0 and for hidden lines\n",
    "    in_range = tf.logical_or(tf.logical_and(yy1s<ygrid, ygrid<=yy2s), tf.logical_and(yy2s<ygrid, ygrid<=yy1s))\n",
    "    in_range = tf.logical_and(in_range, yy2s!=yy1s)\n",
    "    in_range = tf.logical_and(in_range, tf.expand_dims(visible,-1))\n",
    "    xxs = tf.where(in_range, xxs, tf.zeros_like(xxs)) \n",
    "    return tf.nn.top_k(tf.transpose(xxs, perm=(0,2,1)),max_points_per_line).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Font outlines from local font files and write outlines to file for fitting\n",
    "from fontTools.ttLib import TTFont  #pip install fonttools\n",
    "\n",
    "def GetCoordinates(font, glyphName):\n",
    "    \"\"\"font, glyphName --> glyph coordinates as expected by \"gvar\" table\n",
    "    The result includes four \"phantom points\" for the glyph metrics,\n",
    "    as mandated by the \"gvar\" spec.\n",
    "    Function from https://github.com/fonttools/fonttools/blob/master/Snippets/interpolate.py\n",
    "    By inspection coords[0] are all points, and coords[1] are the end of the ranges for each contour (shape)\n",
    "    \"\"\"\n",
    "    glyphTable = font[\"glyf\"]\n",
    "    glyph = glyphTable.glyphs.get(glyphName)\n",
    "    if glyph is None:\n",
    "        return None\n",
    "    glyph.expand(glyphTable)\n",
    "    glyph.recalcBounds(glyphTable)\n",
    "    coords = glyph.getCoordinates(glyphTable)\n",
    "    start=0\n",
    "    contours = []\n",
    "    for end in coords[1]:\n",
    "        contours.append(coords[0][start:end+1])\n",
    "        start=end+1\n",
    "    return contours\n",
    "\n",
    "def readFonts(glyphs, max_points_per_line, ygrid):\n",
    "    glyphinputs = np.identity(len(glyphs), dtype=float)  #input is one-hot vec, one per glyph\n",
    "    files = glob.glob('deeper/*.ttf')\n",
    "    fontvec = np.identity(len(files), dtype=float)  #one-hot vec, one per file\n",
    "    inputs = []\n",
    "    outlines = []\n",
    "    for i, fontfile in enumerate(files):\n",
    "        fontvec = np.zeros(len(files))\n",
    "        fontvec[i]=1\n",
    "        inputs.append(np.concatenate(glyphinputs, fontvec))\n",
    "        outlines.append(generateOutlines(fontfile, glyphs, max_points_per_line, ygrid))\n",
    "    return np.stack(inputs), np.stack(outlines)\n",
    "\n",
    "def generateOutlines(fontfile, glyphs, max_points_per_line, ygrid):\n",
    "    \"\"\"\n",
    "    Read the actual points from all glyphs in the font into numpy array.\n",
    "    Output is array of glyphs x points x 2 (angle in radians, distance).\n",
    "    We use float not the original ints from the font - according to https://github.com/fchollet/keras/issues/2218.\n",
    "    \"\"\"\n",
    "    font = TTFont(fontfile)\n",
    "    unitsPerEm = font['head'].unitsPerEm * 0.9\n",
    "    def angleDist(p1, p2, hidden=False):\n",
    "        \"\"\"Given two point tuples return the angle scaled to [-1,1], and distance scaled similarly\"\"\"\n",
    "        dx = p2[0]-p1[0]\n",
    "        dy = p2[1]-p1[1]\n",
    "        return math.atan2(dy,dx)/math.pi, math.sqrt(dx**2 + dy**2) * (-1 if hidden else 1) / unitsPerEm  #negative distance means hidden\n",
    "    numglyphs = len(glyphs)\n",
    "    outlines = np.zeros((numglyphs, 200), np.float32)\n",
    "    Y = np.zeros((numglyphs, len(ygrid),max_points_per_line), np.float32)\n",
    "    for i, letter in enumerate(glyphs):\n",
    "        contours = GetCoordinates(font, letter)\n",
    "        outline = []\n",
    "        startp = (0,0.1)\n",
    "        #ttx contours are areas within the glyph, like the outside and inside outlines of an O\n",
    "        for xy in contours:\n",
    "            #fill output matrix, start with hidden line to start position\n",
    "            outline += angleDist(startp, xy[0], hidden=True)\n",
    "            startp = xy[0]\n",
    "            #then between points\n",
    "            for n in range(len(xy)-1):\n",
    "                outline += angleDist(xy[n],xy[n+1])\n",
    "            #finally wrap last point to first in contour\n",
    "            N=len(xy)-1\n",
    "            outline += angleDist(xy[N],xy[0])\n",
    "        if len(outline)>outlines.shape[1]: print(\"outline for \"+letter+\" has too many points: \",len(outline))\n",
    "        outlines[i,:len(outline)] = np.array(outline[:outlines.shape[1]], dtype=np.float32)\n",
    "    return outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drawOutlines(outlines, cellsize, scheme):\n",
    "    \"\"\"Draw numpy array interpreted as a glyph per row and each row containing x,y or angle,dist pairs.\"\"\"\n",
    "    columns = math.ceil(800/cellsize)\n",
    "    rows = math.ceil(outlines.shape[0]/columns)\n",
    "    def drawPoints(im, points, cellx, celly):\n",
    "        #temporary image to use to xor each part with main image\n",
    "        im2 = Image.new('1', size=(columns*cellsize, rows*cellsize), color=(0)) \n",
    "        draw = ImageDraw.Draw(im2) \n",
    "        draw.polygon(points, fill=1)\n",
    "        im = ImageChops.logical_xor(im, im2)\n",
    "        return im\n",
    "    scale = cellsize * 0.9\n",
    "    im = Image.new('1', size=(columns*cellsize, rows*cellsize), color=(0)) \n",
    "    for i in range(outlines.shape[0]):\n",
    "        celly,cellx = divmod(i, columns)\n",
    "        cellx *= cellsize\n",
    "        celly *= cellsize\n",
    "        points = []\n",
    "        x,y=(0,cellsize-1)\n",
    "        for j in range(0, outlines.shape[1], 2):\n",
    "            if scheme == Scheme.XY:\n",
    "                x = outlines[i][j]*scale\n",
    "                y = -outlines[i][j+1]*scale\n",
    "                visible = x>0 or y>0\n",
    "            elif scheme == Scheme.DXDY:\n",
    "                x += outlines[i][j]*scale\n",
    "                y -= outlines[i][j+1]*scale\n",
    "                visible = x>0 or y>0\n",
    "            elif scheme == Scheme.ANGDIST:\n",
    "                angle = outlines[i][j]\n",
    "                dist = outlines[i][j+1]\n",
    "                x += abs(dist)*math.cos(angle*math.pi)*scale\n",
    "                y -= abs(dist)*math.sin(angle*math.pi)*scale\n",
    "                visible = dist>0\n",
    "            if visible:\n",
    "                points += (cellx+x,celly+y)\n",
    "            elif len(points)>2:\n",
    "                im = drawPoints(im, points, cellx, celly)\n",
    "                points=[]\n",
    "        if len(points)>2:\n",
    "            im = drawPoints(im, points, cellx, celly)\n",
    "    return im\n",
    "\n",
    "def drawXYs(xxs, ygrid, cellsize):\n",
    "    '''Draw a glyph rasterisation based on a input y coord array with array of x-intercepts of lines with the y coord'''\n",
    "    columns = math.ceil(800/cellsize)\n",
    "    rows = math.ceil(xxs.shape[0]/columns)\n",
    "    scale = cellsize * 0.9\n",
    "    im = Image.new('1', size=(columns*cellsize, rows*cellsize), color=(0)) \n",
    "    draw = ImageDraw.Draw(im) \n",
    "    for i in range(xxs.shape[0]):\n",
    "        yy,xx = divmod(i, columns)\n",
    "        xx *= cellsize\n",
    "        yy = (yy+1)*cellsize-1\n",
    "        for xs, y in zip(xxs[i], ygrid):\n",
    "            for x in xs:\n",
    "                if x>0.0:\n",
    "                    draw.ellipse((xx+x*scale, yy-y*scale, xx+x*scale+3, yy-y*scale+3), fill=1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup...\n",
      "outline shape:  (62, 200)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyAAAADIAQAAAAA49Li3AAAOEUlEQVR4nO2cvW4dSXbHf1X3QrcD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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=800x200 at 0x1241AA53978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('setup...')\n",
    "glyphs = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "glyphs += [chr(i) for i in range(ord('a'), ord('z')+1)]\n",
    "glyphs += ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "#glyphs = ['A','B','a','b','one','two']\n",
    "max_points_per_line = 10 # required for g, m\n",
    "y_divisions = 20\n",
    "ygrid = np.linspace(0.0, 1.0, y_divisions, endpoint=False) #y coordinates to render on\n",
    "#inputs, outlines = readFonts(glyphs, max_points_per_line, ygrid)\n",
    "inputs = np.identity(len(glyphs), dtype=float)  #input is one-hot vec, one per glyph\n",
    "outlines = generateOutlines('deeper/Courier Prime.ttf', glyphs, max_points_per_line, ygrid)\n",
    "print(\"outline shape: \", outlines.shape)\n",
    "scheme = Scheme.ANGDIST\n",
    "#with tf.Session() as sess:\n",
    "#    xcoords = renderGlyphs(outlines, max_points_per_line, ygrid, scheme).eval()\n",
    "    #print(xcoords)\n",
    "#    print(\"output shape: \", xcoords.shape)\n",
    "cellsize = 50\n",
    "drawOutlines(outlines, cellsize, scheme)\n",
    "#display(drawOutlines(outlines, cellsize, scheme), drawXYs(xcoords, ygrid, cellsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile models...\n",
      "80 (4960, 20, 2) (4960, 2)\n",
      "[[[ 0.1  -0.23]\n",
      "  [ 0.    0.02]\n",
      "  [-0.26  0.02]\n",
      "  [-0.5   0.02]\n",
      "  [-0.5   0.02]\n",
      "  [-0.74  0.02]\n",
      "  [ 1.    0.02]\n",
      "  [ 1.    0.18]\n",
      "  [ 1.    0.02]\n",
      "  [ 0.74  0.02]\n",
      "  [ 0.5   0.02]\n",
      "  [ 0.5   0.02]\n",
      "  [ 0.26  0.02]\n",
      "  [ 0.    0.02]\n",
      "  [ 0.    0.03]\n",
      "  [ 0.39  0.53]\n",
      "  [ 1.    0.1 ]\n",
      "  [ 1.    0.02]\n",
      "  [ 0.74  0.02]\n",
      "  [ 0.5   0.02]]\n",
      "\n",
      " [[ 0.    0.02]\n",
      "  [-0.26  0.02]\n",
      "  [-0.5   0.02]\n",
      "  [-0.5   0.02]\n",
      "  [-0.74  0.02]\n",
      "  [ 1.    0.02]\n",
      "  [ 1.    0.18]\n",
      "  [ 1.    0.02]\n",
      "  [ 0.74  0.02]\n",
      "  [ 0.5   0.02]\n",
      "  [ 0.5   0.02]\n",
      "  [ 0.26  0.02]\n",
      "  [ 0.    0.02]\n",
      "  [ 0.    0.03]\n",
      "  [ 0.39  0.53]\n",
      "  [ 1.    0.1 ]\n",
      "  [ 1.    0.02]\n",
      "  [ 0.74  0.02]\n",
      "  [ 0.5   0.02]\n",
      "  [ 0.5   0.02]]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (80, 20, 20)              1840      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (80, 20, 20)              3280      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (80, 400)                 0         \n",
      "_________________________________________________________________\n",
      "outlines (Dense)             (80, 2)                   802       \n",
      "=================================================================\n",
      "Total params: 5,922\n",
      "Trainable params: 5,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('compile models...')\n",
    "timesteps = 5\n",
    "#indices = np.zeros(shape=(timesteps, len(inputs)-timesteps), dtype=np.int32)\n",
    "#for i in range(timesteps):\n",
    "#    indices[i,:] = np.arange(i, i+len(inputs)-timesteps)\n",
    "outlines = np.reshape(outlines, (outlines.shape[0], -1, 2))\n",
    "#print(outlines.shape, outlines[0][:10])\n",
    "batch_size = outlines.shape[1]-timesteps\n",
    "#inputs->outputs:\n",
    "#A1, A2, A3... -> A6\n",
    "#A2, A3, A4... -> A7\n",
    "#...\n",
    "#B1, B2, B3... -> B6\n",
    "inputs2 = np.stack([r[i:i+timesteps] for r in outlines for i in range(batch_size)])\n",
    "outputs2 = np.stack([r[i+timesteps] for r in outlines for i in range(batch_size)])\n",
    "print(batch_size, inputs2.shape, outputs2.shape)\n",
    "print(inputs2[0:2])\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Dense(50, input_dim=inputs.shape[1]))\n",
    "#model.add(layers.Lambda(lambda inputs: tf.gather(inputs, indices, axis=1), name='gather'))\n",
    "model.add(layers.LSTM(20, batch_input_shape=(batch_size, timesteps, 2), dropout=0.1, return_sequences=True, stateful=True))\n",
    "model.add(layers.LSTM(20, dropout=0.1, recurrent_dropout=0.1, return_sequences=True, stateful=True))\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(20))#, activation='relu'))\n",
    "#model.add(layers.Dropout(0.20))\n",
    "#model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(2, name='outlines'))\n",
    "#scheme = Scheme.ANGDIST\n",
    "#model.add(layers.Lambda(lambda outline: renderGlyphs(outline, max_points_per_line, ygrid, scheme), name='renderGlyph'))\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
    "##grab a model excluding final rendering layer for fitting/predicting outlines only\n",
    "#outlines_model = models.Model(inputs=model.input, outputs=model.get_layer('outlines').output)\n",
    "#outlines_model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
    "#print(\"outlines_model.output_shape\", outlines_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model...\n",
      "view using:\n",
      "tensorboard --logdir=C:\\src\\Repos\\ipython_notebooks\\logs\n",
      "Epoch 1/100\n",
      "2s - loss: 0.0375 - mean_absolute_error: 0.0920\n",
      "Epoch 2/100\n",
      "2s - loss: 0.0376 - mean_absolute_error: 0.0918\n",
      "Epoch 3/100\n",
      "2s - loss: 0.0372 - mean_absolute_error: 0.0908\n",
      "Epoch 4/100\n",
      "2s - loss: 0.0370 - mean_absolute_error: 0.0913\n",
      "Epoch 5/100\n",
      "2s - loss: 0.0358 - mean_absolute_error: 0.0903\n",
      "Epoch 6/100\n",
      "2s - loss: 0.0366 - mean_absolute_error: 0.0903\n",
      "Epoch 7/100\n",
      "1s - loss: 0.0351 - mean_absolute_error: 0.0892\n",
      "Epoch 8/100\n",
      "1s - loss: 0.0356 - mean_absolute_error: 0.0893\n",
      "Epoch 9/100\n",
      "1s - loss: 0.0356 - mean_absolute_error: 0.0883\n",
      "Epoch 10/100\n",
      "2s - loss: 0.0337 - mean_absolute_error: 0.0876\n",
      "Epoch 11/100\n",
      "2s - loss: 0.0348 - mean_absolute_error: 0.0885\n",
      "Epoch 12/100\n",
      "1s - loss: 0.0358 - mean_absolute_error: 0.0882\n",
      "Epoch 13/100\n",
      "1s - loss: 0.0360 - mean_absolute_error: 0.0891\n",
      "Epoch 14/100\n",
      "1s - loss: 0.0349 - mean_absolute_error: 0.0890\n",
      "Epoch 15/100\n",
      "1s - loss: 0.0338 - mean_absolute_error: 0.0879\n",
      "Epoch 16/100\n",
      "1s - loss: 0.0339 - mean_absolute_error: 0.0868\n",
      "Epoch 17/100\n",
      "1s - loss: 0.0337 - mean_absolute_error: 0.0858\n",
      "Epoch 18/100\n",
      "1s - loss: 0.0346 - mean_absolute_error: 0.0880\n",
      "Epoch 19/100\n",
      "1s - loss: 0.0334 - mean_absolute_error: 0.0862\n",
      "Epoch 20/100\n",
      "1s - loss: 0.0326 - mean_absolute_error: 0.0848\n",
      "Epoch 21/100\n",
      "1s - loss: 0.0324 - mean_absolute_error: 0.0853\n",
      "Epoch 22/100\n",
      "2s - loss: 0.0318 - mean_absolute_error: 0.0842\n",
      "Epoch 23/100\n",
      "1s - loss: 0.0327 - mean_absolute_error: 0.0864\n",
      "Epoch 24/100\n",
      "1s - loss: 0.0329 - mean_absolute_error: 0.0850\n",
      "Epoch 25/100\n",
      "1s - loss: 0.0323 - mean_absolute_error: 0.0859\n",
      "Epoch 26/100\n",
      "1s - loss: 0.0322 - mean_absolute_error: 0.0851\n",
      "Epoch 27/100\n",
      "1s - loss: 0.0329 - mean_absolute_error: 0.0853\n",
      "Epoch 28/100\n",
      "1s - loss: 0.0316 - mean_absolute_error: 0.0843\n",
      "Epoch 29/100\n",
      "1s - loss: 0.0308 - mean_absolute_error: 0.0832\n",
      "Epoch 30/100\n",
      "1s - loss: 0.0318 - mean_absolute_error: 0.0836\n",
      "Epoch 31/100\n",
      "1s - loss: 0.0310 - mean_absolute_error: 0.0835\n",
      "Epoch 32/100\n",
      "1s - loss: 0.0315 - mean_absolute_error: 0.0846\n",
      "Epoch 33/100\n",
      "1s - loss: 0.0316 - mean_absolute_error: 0.0844\n",
      "Epoch 34/100\n",
      "1s - loss: 0.0302 - mean_absolute_error: 0.0821\n",
      "Epoch 35/100\n",
      "1s - loss: 0.0298 - mean_absolute_error: 0.0823\n",
      "Epoch 36/100\n",
      "1s - loss: 0.0297 - mean_absolute_error: 0.0824\n",
      "Epoch 37/100\n",
      "1s - loss: 0.0299 - mean_absolute_error: 0.0819\n",
      "Epoch 38/100\n",
      "1s - loss: 0.0297 - mean_absolute_error: 0.0819\n",
      "Epoch 39/100\n",
      "1s - loss: 0.0302 - mean_absolute_error: 0.0823\n",
      "Epoch 40/100\n",
      "1s - loss: 0.0307 - mean_absolute_error: 0.0825\n",
      "Epoch 41/100\n",
      "1s - loss: 0.0305 - mean_absolute_error: 0.0826\n",
      "Epoch 42/100\n",
      "1s - loss: 0.0307 - mean_absolute_error: 0.0822\n",
      "Epoch 43/100\n",
      "1s - loss: 0.0292 - mean_absolute_error: 0.0814\n",
      "Epoch 44/100\n",
      "1s - loss: 0.0296 - mean_absolute_error: 0.0823\n",
      "Epoch 45/100\n",
      "1s - loss: 0.0294 - mean_absolute_error: 0.0814\n",
      "Epoch 46/100\n",
      "1s - loss: 0.0288 - mean_absolute_error: 0.0808\n",
      "Epoch 47/100\n",
      "1s - loss: 0.0293 - mean_absolute_error: 0.0812\n",
      "Epoch 48/100\n",
      "1s - loss: 0.0279 - mean_absolute_error: 0.0807\n",
      "Epoch 49/100\n",
      "2s - loss: 0.0287 - mean_absolute_error: 0.0801\n",
      "Epoch 50/100\n",
      "2s - loss: 0.0284 - mean_absolute_error: 0.0799\n",
      "Epoch 51/100\n",
      "1s - loss: 0.0282 - mean_absolute_error: 0.0799\n",
      "Epoch 52/100\n",
      "1s - loss: 0.0286 - mean_absolute_error: 0.0803\n",
      "Epoch 53/100\n",
      "1s - loss: 0.0284 - mean_absolute_error: 0.0799\n",
      "Epoch 54/100\n",
      "1s - loss: 0.0297 - mean_absolute_error: 0.0813\n",
      "Epoch 55/100\n",
      "1s - loss: 0.0269 - mean_absolute_error: 0.0782\n",
      "Epoch 56/100\n",
      "1s - loss: 0.0275 - mean_absolute_error: 0.0791\n",
      "Epoch 57/100\n",
      "1s - loss: 0.0286 - mean_absolute_error: 0.0797\n",
      "Epoch 58/100\n",
      "1s - loss: 0.0278 - mean_absolute_error: 0.0784\n",
      "Epoch 59/100\n",
      "2s - loss: 0.0276 - mean_absolute_error: 0.0785\n",
      "Epoch 60/100\n",
      "1s - loss: 0.0277 - mean_absolute_error: 0.0789\n",
      "Epoch 61/100\n",
      "1s - loss: 0.0270 - mean_absolute_error: 0.0785\n",
      "Epoch 62/100\n",
      "1s - loss: 0.0279 - mean_absolute_error: 0.0788\n",
      "Epoch 63/100\n",
      "1s - loss: 0.0282 - mean_absolute_error: 0.0792\n",
      "Epoch 64/100\n",
      "1s - loss: 0.0273 - mean_absolute_error: 0.0776\n",
      "Epoch 65/100\n",
      "1s - loss: 0.0270 - mean_absolute_error: 0.0777\n",
      "Epoch 66/100\n",
      "1s - loss: 0.0273 - mean_absolute_error: 0.0790\n",
      "Epoch 67/100\n",
      "3s - loss: 0.0275 - mean_absolute_error: 0.0782\n",
      "Epoch 68/100\n",
      "2s - loss: 0.0274 - mean_absolute_error: 0.0771\n",
      "Epoch 69/100\n",
      "2s - loss: 0.0261 - mean_absolute_error: 0.0761\n",
      "Epoch 70/100\n",
      "3s - loss: 0.0262 - mean_absolute_error: 0.0772\n",
      "Epoch 71/100\n",
      "1s - loss: 0.0277 - mean_absolute_error: 0.0784\n",
      "Epoch 72/100\n",
      "1s - loss: 0.0264 - mean_absolute_error: 0.0770\n",
      "Epoch 73/100\n",
      "1s - loss: 0.0266 - mean_absolute_error: 0.0763\n",
      "Epoch 74/100\n",
      "1s - loss: 0.0265 - mean_absolute_error: 0.0770\n",
      "Epoch 75/100\n",
      "2s - loss: 0.0259 - mean_absolute_error: 0.0768\n",
      "Epoch 76/100\n",
      "1s - loss: 0.0253 - mean_absolute_error: 0.0760\n",
      "Epoch 77/100\n",
      "1s - loss: 0.0260 - mean_absolute_error: 0.0769\n",
      "Epoch 78/100\n",
      "2s - loss: 0.0249 - mean_absolute_error: 0.0757\n",
      "Epoch 79/100\n",
      "2s - loss: 0.0254 - mean_absolute_error: 0.0756\n",
      "Epoch 80/100\n",
      "2s - loss: 0.0261 - mean_absolute_error: 0.0764\n",
      "Epoch 81/100\n",
      "2s - loss: 0.0257 - mean_absolute_error: 0.0761\n",
      "Epoch 82/100\n",
      "2s - loss: 0.0248 - mean_absolute_error: 0.0751\n",
      "Epoch 83/100\n",
      "2s - loss: 0.0254 - mean_absolute_error: 0.0753\n",
      "Epoch 84/100\n",
      "2s - loss: 0.0247 - mean_absolute_error: 0.0750\n",
      "Epoch 85/100\n",
      "2s - loss: 0.0239 - mean_absolute_error: 0.0741\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0b795f10d964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'view using:\\ntensorboard --logdir='\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, histogram_freq=10000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;31m#for i in range(epochs):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m#    model.fit(inputs2, outputs2, epochs=1, batch_size=batch_size, verbose=2, shuffle=False, callbacks=[board])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('fitting model...')\n",
    "epochs=100\n",
    "logs = 'logs/deeperlstm2020'\n",
    "print('view using:\\ntensorboard --logdir='+os.path.abspath('logs'))\n",
    "board = TensorBoard(log_dir=logs)#, histogram_freq=10000)\n",
    "model.fit(inputs2, outputs2, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=[board], shuffle=False)\n",
    "#for i in range(epochs):\n",
    "#    model.fit(inputs2, outputs2, epochs=1, batch_size=batch_size, verbose=2, shuffle=False, callbacks=[board])\n",
    "#    model.reset_states()\n",
    "scores = model.evaluate(inputs2, outputs2, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict outlines...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 20, 2) for Tensor 'lstm_5_input:0', which has shape '(80, 20, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-566f5f4efd41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnewoutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#start with existing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnewoutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewoutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnewoutlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewoutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1517\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 20, 2) for Tensor 'lstm_5_input:0', which has shape '(80, 20, 2)'"
     ]
    }
   ],
   "source": [
    "print('predict outlines...')\n",
    "newoutlines = np.zeros_like(outlines)\n",
    "for g in range(len(glyphs)):\n",
    "    newoutput = np.zeros_like(outlines[g])\n",
    "    newoutput[0:timesteps] = outlines[g][0:timesteps] #start with existing\n",
    "    for i in range(batch_size):\n",
    "        newoutput[i+timesteps] = np.reshape(model.predict(np.reshape(newoutput[i:i+timesteps], (1, timesteps, 2)), verbose=0), (2))\n",
    "    newoutlines[g] = newoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(np.concatenate((outlines[0], outlines[2]), axis=1))\n",
    "print(np.stack((outlines[1].flatten(), newoutlines[1].flatten()), axis=-1).flatten())\n",
    "drawOutlines(np.reshape(newoutlines,(len(glyphs),-1)), cellsize, scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4736/4898 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyAAADv2AQAAAACs4C/CAAAF9UlEQVR4nO3BgQAAAADDoPlTn+AG\nVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAA8A2pZwAB1u6aGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=800x15350 at 0x2178471BF98>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now, what happens when we predict mixed glyphs?\n",
    "mixed_outlines = model.predict(np.random.random(inputs2.shape), verbose=1)\n",
    "drawOutlines(mixed_outlines, cellsize, scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#what about interpolating between glyphs?  let's try gradually mixing A into B\n",
    "#need array [[1, 0, ...], [1, 0.1, ...]]\n",
    "A = inputs[0]\n",
    "B = inputs[1]\n",
    "steps=12\n",
    "mix = np.array([A*(steps-i)/steps + i*B/steps for i in range(steps+1)])\n",
    "#print(mix[:3])\n",
    "interp = outlines_model.predict(mix, verbose=1)\n",
    "drawOutlines(interp, cellsize, scheme)\n",
    "#not very convincing :(, perhaps raw points rather than angle, dist pairs for the outline would be better\n",
    "#also need to try interpolating A between two fonts"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
