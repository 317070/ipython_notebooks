{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeperfont\n",
    "*[Website](http://nbviewer.jupyter.org/github/terryspitz/ipython_notebooks/blob/master/deeperfont.ipynb)*\n",
    "\n",
    "Deeperfont is a Neural Network attempt at the 'Font Problem' - how to capture the essence of a font in such a way as to generalise to unseen letters and to allow interpolation between different fonts.\n",
    "\n",
    "Initial research suggested the use of [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/) as best practise for both getting started and long-term research.  As output the network will generate a set of font outlines or [glyphs](https://en.wikipedia.org/wiki/Glyph).  The encoding of outputs has been considered in two ways: raw (x,y) coordinates, as expressed in the TTF font glyphs, or a conversion of these outlines to (angle, distance) pairs as in [Turtle graphics](https://en.wikipedia.org/wiki/Turtle_graphics) (best known for it's  use in [Logo](https://en.wikipedia.org/wiki/Logo_(programming_language).)\n",
    "\n",
    "Considering the evaluation function we note that the exact sequence of points in the glyph can be varied while generating identical rendered output, for example a line segment can be split into a number of smaller colinear segments.  The network should be free to express its results in any equivalent way.  The evaluation function is therefore required to compare rendered output.  We build an evaluation function in pure Tensorflow using a [scanline algorithm](https://en.wikipedia.org/wiki/Scanline_rendering) to generate a tensor containing the x coordinates of the outline for a set of equi-spaced y line.  The predicted and true outlines are then compared by calculating the difference in visible pixels.\n",
    "\n",
    "While the network will output the outline into the Y variable, the Y_true will store a rendered outline to be consumed directly by the evaluation function.\n",
    "\n",
    "As input we provide the letter to render, in the form of a [one-hot](https://en.wikipedia.org/wiki/One-hot) vector.\n",
    "\n",
    "See also:\n",
    "* [MetaFont](https://en.wikipedia.org/wiki/Metafont)\n",
    "* [Metaflop - interactive MetaFont](http://www.metaflop.com/modulator)\n",
    "* [deepfont](https://erikbern.com/2016/01/21/analyzing-50k-fonts-using-deep-neural-networks.html)\n",
    "* https://arxiv.org/abs/1507.03196\n",
    "* https://pypi.python.org/pypi/FontTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw, ImageChops, ImageFont\n",
    "from keras.models import Sequential\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def renderGlyphs(gls, max_points_per_line, ygrid):\n",
    "    '''\n",
    "    Pure tensorflow function\n",
    "    Input: 2D list of letters * glyph outlines as (angle, distance) pairs \n",
    "    Output: letters * matrix of sorted top x coords for each line per y coording\n",
    "    '''\n",
    "    angles = gls[:,::2]\n",
    "    dists = gls[:,1::2]\n",
    "\n",
    "    linexs = tf.cumsum(tf.abs(dists)*tf.cos(angles*math.pi), axis=-1)+1e-4\n",
    "    x1s = linexs[:,:-1]\n",
    "    x2s = linexs[:,1:]\n",
    "    lineys = tf.cumsum(tf.abs(dists)*tf.sin(angles*math.pi), axis=-1)+1e-4\n",
    "    y1s = lineys[:,:-1]\n",
    "    y2s = lineys[:,1:]\n",
    "\n",
    "    xx1s=tf.expand_dims(x1s,-1)\n",
    "    xx2s=tf.expand_dims(x2s,-1)\n",
    "    yy1s=tf.expand_dims(y1s,-1)\n",
    "    yy2s=tf.expand_dims(y2s,-1)\n",
    "\n",
    "    #interpolate the x coords for all lines at all y coord\n",
    "    xxs = xx1s + (xx2s-xx1s)*(ygrid-yy1s)/(yy2s-yy1s)\n",
    "    in_range = tf.logical_or(tf.logical_and(yy1s<ygrid, ygrid<=yy2s), tf.logical_and(yy2s<ygrid, ygrid<=yy1s))\n",
    "    xxs = tf.cast(in_range, tf.float32) * xxs * tf.expand_dims(tf.sign(dists[:,1:]),-1)\n",
    "    return tf.nn.top_k(tf.transpose(xxs, perm=(0,2,1)),max_points_per_line).values\n",
    "\n",
    "def drawGlyph(xxs, ygrid):\n",
    "    '''Draw a glyph rasterisation based on a input y coord array with array of x-intercepts of lines with the y coord'''\n",
    "    size = 500\n",
    "    im = Image.new('1', size=(size, size), color=(0)) \n",
    "    draw = ImageDraw.Draw(im) \n",
    "    for xs, y in zip(xxs, ygrid):\n",
    "        for x in xs:\n",
    "            if x>0.0:\n",
    "                draw.ellipse((x*size, (1.0-y)*size, x*size+3, (1.0-y)*size+3), fill=1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def angleDist(p1, p2, hidden, unitsPerEm):\n",
    "    \"\"\"Given two point tuples return the angle scaled to [-1,1], and distance scaled similarly\"\"\"\n",
    "    dx = p2[0]-p1[0]\n",
    "    dy = p2[1]-p1[1]\n",
    "    return math.atan2(dy,dx)/math.pi, math.sqrt(dx**2 + dy**2) * (-1 if hidden else 1) / unitsPerEm  #negative distance means hidden\n",
    "\n",
    "def generateTrueOutput(ttx, letters, max_points_per_line, ygrid):\n",
    "    \"\"\"\n",
    "    Read the actual points from all letters in the font into numpy array.\n",
    "    Output is array of letters x points x 2 (angle in radians, distance).\n",
    "    We use float according to https://github.com/fchollet/keras/issues/2218.\n",
    "    \"\"\"\n",
    "    \n",
    "    unitsPerEm = int(ttx.find('head/unitsPerEm').get('value'))\n",
    "    numletters = len(letters)\n",
    "    outlines = np.zeros((numletters, 200), np.float32)\n",
    "    Y = np.zeros((numletters, len(ygrid),max_points_per_line), np.float32)\n",
    "    for i, l in enumerate(letters):\n",
    "        glyph = ttx.find(r\".//TTGlyph[@name='\"+l+\"']\")\n",
    "        outline = []\n",
    "        p=0 #point count across all contours (shapes)\n",
    "        startp = (0,0)\n",
    "\n",
    "        #ttx contours are areas within the letter, like the outside and inside of an O\n",
    "        for contour in glyph.iterfind('contour'):\n",
    "            pts = contour.iterfind('pt')\n",
    "            xy = [(int(pt.get('x')), int(pt.get('y'))) for pt in pts] #should read the ttx 'on' attribute too for bezier control points\n",
    "            #fill output matrix, start with hidden line to start position\n",
    "            outline += angleDist(startp, xy[0], True, unitsPerEm)\n",
    "            startp = xy[0]\n",
    "            p+=2\n",
    "            #then between points\n",
    "            for n in range(len(xy)-1):\n",
    "                outline += angleDist(xy[n],xy[n+1], False, unitsPerEm)\n",
    "                p+=2\n",
    "            #finally wrap last point to first in contour\n",
    "            N=len(xy)-1\n",
    "            outline += angleDist(xy[N],xy[0], False, unitsPerEm)\n",
    "            p+=2\n",
    "        outlines[i,:len(outline)] = np.array(outline, dtype=np.float32)\n",
    "    return renderGlyphs(outlines, max_points_per_line, ygrid)\n",
    "\n",
    "def setupInputOutputRender(ttx, letters, outputdim):\n",
    "    \"\"\"\n",
    "    Generate target output by rendering each glyph and reading X coords of the outline.\n",
    "    Target Output is matrix of x coords of outline for each y coord\n",
    "    We use float not int according to https://github.com/fchollet/keras/issues/2218.\n",
    "    \"\"\"\n",
    "    numletters = len(letters)\n",
    "    Y = np.zeros((numletters, outputdim*2), np.float32)\n",
    "    for i, letter in enumerate(letters):\n",
    "        im = Image.new('1', size=(cellsize, cellsize), color=(0)) \n",
    "        draw = ImageDraw.Draw(im) \n",
    "        fnt = ImageFont.truetype('deeper/Quicksand-Bold.otf', cellsize)\n",
    "        draw.text((10,10), letter, font=fnt, fill=1)\n",
    "        im = ImageChops.logical_xor(im,  ImageChops.offset(im, 1, 0))\n",
    "        print(im.tobytes())\n",
    "        Y[i] = np.fromstring(im.tobytes())\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def drawAllLetters(Y):\n",
    "    \"\"\"Draw numpy array interpreted as a letter per row and each row containing (angle, dist) pairs.\"\"\"\n",
    "    columns = 13\n",
    "    rows = math.ceil(Y.shape[0]/columns)\n",
    "    def drawPoints(im, points):\n",
    "        #temporary image to use to xor each part with main image\n",
    "        im2 = Image.new('1', size=(columns*cellsize, rows*cellsize), color=(0)) \n",
    "        draw = ImageDraw.Draw(im2) \n",
    "        draw.polygon(points, fill=1)\n",
    "        im = ImageChops.logical_xor(im, im2)\n",
    "        return im\n",
    "    scale = cellsize * 0.8\n",
    "    im = Image.new('1', size=(columns*cellsize, rows*cellsize), color=(0)) \n",
    "    for i in range(Y.shape[0]):\n",
    "        y,x = divmod(i, columns)\n",
    "        x *= cellsize\n",
    "        y = (y+1)*cellsize-1\n",
    "        points = []\n",
    "        for j in range(0, Y.shape[1], 2):\n",
    "            angle = Y[i][j]\n",
    "            dist = Y[i][j+1]\n",
    "            x2 = x+ abs(dist)*math.cos(angle*math.pi)*scale\n",
    "            y2 = y- abs(dist)*math.sin(angle*math.pi)*scale\n",
    "            if dist>0:\n",
    "                points += (x2,y2)\n",
    "            elif len(points)>2:\n",
    "                im = drawPoints(im, points)\n",
    "                points=[]\n",
    "            x=x2\n",
    "            y=y2\n",
    "    if len(points)>2:\n",
    "        im = drawPoints(im, points)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup...\n",
      "Tensor(\"TopKV2_3:0\", shape=(2, 100, 6), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH0AQAAAADjreInAAAGKElEQVR4nO2cPY7cOBCFX7cHmMEG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\nf9Euvf7/F2varl69jm67/wBjoQGcD4wzTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=500x500 at 0x1DFAF0FC0F0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('setup...')\n",
    "letters = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "letters += [chr(i) for i in range(ord('a'), ord('z')+1)]\n",
    "letters += ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "letters = ['A','B']\n",
    "np.set_printoptions(precision=2)\n",
    "ttx = ET.parse(r'deeper/BASKVILL.ttx') #read font data dumped from TrueType using fonttools\n",
    "#outputdim = readFont(ttx, letters)\n",
    "max_points_per_line = 6\n",
    "ygrid = np.linspace(0.0, 1.0, 100, endpoint=False) #y coordinates to render on\n",
    "X = np.identity(len(letters), dtype=float)  #input is 'one-hot' array, one per letter\n",
    "with tf.Session() as sess:\n",
    "    Y_true = generateTrueOutput(ttx, letters, max_points_per_line, ygrid)\n",
    "    print(Y_true)\n",
    "    #drawAllLetters(Y)\n",
    "    #xxs = renderGlyph(tf.constant(Y[1]), max_points_per_line, ygrid)\n",
    "    im = drawGlyph(Y_true.eval()[1], ygrid)\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile model...\n",
      "fit the model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1ecb1776f0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit the model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \"\"\"\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3912\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   3915\u001b[0m                        \u001b[1;34m\"session is registered. Use `with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m                        \u001b[1;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "def glyphDiffTF(y_true, y_pred):\n",
    "    return tf.reduce_max(renderGlyph(y_true, max_points_per_line, ygrid), axis=0)#-tf.reduce_min(glyph(y_pred, axis=1)) \n",
    "\n",
    "print('compile model...')\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(20, input_dim=X.shape[1]))\n",
    "#model.add(Dense(600, activation='relu'))\n",
    "#model.add(LSTM(4))#, return_sequences=True))\n",
    "model.add(layers.Dense(30, name='outlines'))\n",
    "model.add(layers.Lambda(lambda outline:renderGlyphs(outline, max_points_per_line, ygrid), name='renderGlyph'))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print('fit the model...')\n",
    "model.fit(X, Y_true.eval(), epochs=500, batch_size=len(letters), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('evaluate the model...')\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "print('predict outlines...')\n",
    "outlines_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer('outlines').output)\n",
    "newY = outlines_model.predict(X, verbose=1)\n",
    "\n",
    "print(\"true vs pred:\")\n",
    "print(Y[0][:20])\n",
    "print(newY[0][:20])\n",
    "drawAllLetters(newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now, what happens when we predict mixed letters?\n",
    "newY = model.predict(np.random.random(X.shape), verbose=1)\n",
    "drawAllLetters(newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#what about interpolating between letters?  let's try gradually mixing A into B\n",
    "#need array [[1, 0, ...], [1, 0.1, ...]]\n",
    "A = X[0]\n",
    "B = X[1]\n",
    "steps=12\n",
    "mix = np.array([A*(steps-i)/steps + i*B/steps for i in range(steps+1)])\n",
    "#print(mix[:3])\n",
    "newY = model.predict(mix, verbose=1)\n",
    "drawAllLetters(newY)\n",
    "#not very convincing :(, perhaps raw points rather than angle, dist pairs for the outline would be better\n",
    "#also need to try interpolating A between two fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
