{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeperfont\n",
    "*[Website](http://nbviewer.jupyter.org/github/terryspitz/ipython_notebooks/blob/master/deeperfont.ipynb)*\n",
    "\n",
    "Deeperfont is a Neural Network attempt at the 'Font Problem' - how to capture the essence of a font in such a way as to generalise to unseen letters and to allow interpolation between different fonts.\n",
    "\n",
    "Initial research suggested the use of [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/) as best practise for both getting started and long-term research.  As output the network will generate a set of font outlines or [glyphs](https://en.wikipedia.org/wiki/Glyph).  The encoding of outputs has been considered in two ways: raw (x,y) coordinates, as expressed in the TTF font glyphs, or a conversion of these outlines to (angle, distance) pairs as in [Turtle graphics](https://en.wikipedia.org/wiki/Turtle_graphics) (best known for it's  use in [Logo](https://en.wikipedia.org/wiki/Logo_(programming_language).)\n",
    "\n",
    "Considering the evaluation function we note that the exact sequence of points in the glyph can be varied while generating identical rendered output, for example a line segment can be split into a number of smaller colinear segments.  The network should be free to express its results in any equivalent way.  The evaluation function is therefore required to compare rendered output.  We build an evaluation function in pure Tensorflow using a [scanline algorithm](https://en.wikipedia.org/wiki/Scanline_rendering) to generate a tensor containing the x coordinates of the outline for a set of equi-spaced y line.  The predicted and true outlines are then compared by calculating the difference in visible pixels.\n",
    "\n",
    "While the network will output the outline into the Y variable, the Y_true will store a rendered outline to be consumed directly by the evaluation function.\n",
    "\n",
    "As input we provide the letter to render, in the form of a [one-hot](https://en.wikipedia.org/wiki/One-hot) vector.\n",
    "\n",
    "See also:\n",
    "* [MetaFont](https://en.wikipedia.org/wiki/Metafont)\n",
    "* [Metaflop - interactive MetaFont](http://www.metaflop.com/modulator)\n",
    "* [deepfont](https://erikbern.com/2016/01/21/analyzing-50k-fonts-using-deep-neural-networks.html)\n",
    "* https://arxiv.org/abs/1507.03196\n",
    "* https://pypi.python.org/pypi/FontTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw, ImageChops, ImageFont\n",
    "from keras.models import Sequential\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def renderGlyph(gl, max_points_per_line, ygrid):\n",
    "    '''\n",
    "    Pure tensorflow function\n",
    "    Input: 1D list of glyph outlines as (angle, distance) pairs \n",
    "    Output: matrix of sorted top x coords for each line per y coording\n",
    "    '''\n",
    "    angles = gl[::2]\n",
    "    dists = gl[1::2]\n",
    "\n",
    "    linexs = tf.cumsum(tf.abs(dists)*tf.cos(angles*math.pi))+1e-4\n",
    "    x1s = linexs[:-1]\n",
    "    x2s = linexs[1:]\n",
    "    lineys = tf.cumsum(tf.abs(dists)*tf.sin(angles*math.pi))+1e-4\n",
    "    y1s = lineys[:-1]\n",
    "    y2s = lineys[1:]\n",
    "\n",
    "    xx1s=tf.expand_dims(x1s,-1)\n",
    "    xx2s=tf.expand_dims(x2s,-1)\n",
    "    yy1s=tf.expand_dims(y1s,-1)\n",
    "    yy2s=tf.expand_dims(y2s,-1)\n",
    "\n",
    "    #interpolate the x coords for all lines at all y coord\n",
    "    xxs = xx1s + (xx2s-xx1s)*(ygrid-yy1s)/(yy2s-yy1s)\n",
    "    in_range = tf.logical_or(tf.logical_and(yy1s<ygrid, ygrid<=yy2s), tf.logical_and(yy2s<ygrid, ygrid<=yy1s))\n",
    "    xxs = tf.cast(in_range, tf.float32) * xxs * tf.expand_dims(tf.sign(dists[1:]),-1)\n",
    "    return tf.nn.top_k(tf.transpose(xxs),max_points_per_line).values\n",
    "\n",
    "def drawGlyph(xxs, ygrid):\n",
    "    '''Draw a glyph rasterisation based on a input y coord array with array of x-intercepts of lines with the y coord'''\n",
    "    size = 500\n",
    "    im = Image.new('1', size=(size, size), color=(0)) \n",
    "    draw = ImageDraw.Draw(im) \n",
    "    for xs, y in zip(xxs, ygrid):\n",
    "        for x in xs:\n",
    "            if x>0.0:\n",
    "                draw.ellipse((x*size, (1.0-y)*size, x*size+3, (1.0-y)*size+3), fill=1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def angleDist(p1, p2, hidden, unitsPerEm):\n",
    "    \"\"\"Given two point tuples return the angle scaled to [-1,1], and distance scaled similarly\"\"\"\n",
    "    dx = p2[0]-p1[0]\n",
    "    dy = p2[1]-p1[1]\n",
    "    return math.atan2(dy,dx)/math.pi, math.sqrt(dx**2 + dy**2) * (-1 if hidden else 1) / unitsPerEm  #negative distance means hidden\n",
    "\n",
    "def generateTrueOutput(ttx, letters, max_points_per_line, ygrid):\n",
    "    \"\"\"\n",
    "    Read the actual points from all letters in the font into numpy array.\n",
    "    Output is array of letters x points x 2 (angle in radians, distance).\n",
    "    We use float according to https://github.com/fchollet/keras/issues/2218.\n",
    "    \"\"\"\n",
    "    \n",
    "    unitsPerEm = int(ttx.find('head/unitsPerEm').get('value'))\n",
    "    numletters = len(letters)\n",
    "    Y = np.zeros((numletters, len(ygrid),max_points_per_line), np.float32)\n",
    "    for i, l in enumerate(letters):\n",
    "        glyph = ttx.find(r\".//TTGlyph[@name='\"+l+\"']\")\n",
    "        outline = []\n",
    "        p=0 #point count across all contours (shapes)\n",
    "        startp = (0,0)\n",
    "\n",
    "        #ttx contours are areas within the letter, like the outside and inside of an O\n",
    "        for contour in glyph.iterfind('contour'):\n",
    "            pts = contour.iterfind('pt')\n",
    "            xy = [(int(pt.get('x')), int(pt.get('y'))) for pt in pts] #should read the ttx 'on' attribute too for bezier control points\n",
    "            #fill output matrix, start with hidden line to start position\n",
    "            outline += angleDist(startp, xy[0], True, unitsPerEm)\n",
    "            startp = xy[0]\n",
    "            p+=2\n",
    "            #then between points\n",
    "            for n in range(len(xy)-1):\n",
    "                outline += angleDist(xy[n],xy[n+1], False, unitsPerEm)\n",
    "                p+=2\n",
    "            #finally wrap last point to first in contour\n",
    "            N=len(xy)-1\n",
    "            outline += angleDist(xy[N],xy[0], False, unitsPerEm)\n",
    "            p+=2\n",
    "        print\n",
    "        xxs = renderGlyph(np.array(outline, dtype=np.float32), max_points_per_line, ygrid)\n",
    "        #print(xxs.eval())\n",
    "        Y[i] = xxs.eval()\n",
    "    return Y\n",
    "\n",
    "def setupInputOutputRender(ttx, letters, outputdim):\n",
    "    \"\"\"\n",
    "    Generate target output by rendering each glyph and reading X coords of the outline.\n",
    "    Target Output is matrix of x coords of outline for each y coord\n",
    "    We use float not int according to https://github.com/fchollet/keras/issues/2218.\n",
    "    \"\"\"\n",
    "    numletters = len(letters)\n",
    "    Y = np.zeros((numletters, outputdim*2), np.float32)\n",
    "    for i, letter in enumerate(letters):\n",
    "        im = Image.new('1', size=(cellsize, cellsize), color=(0)) \n",
    "        draw = ImageDraw.Draw(im) \n",
    "        fnt = ImageFont.truetype('deeper/Quicksand-Bold.otf', cellsize)\n",
    "        draw.text((10,10), letter, font=fnt, fill=1)\n",
    "        im = ImageChops.logical_xor(im,  ImageChops.offset(im, 1, 0))\n",
    "        print(im.tobytes())\n",
    "        Y[i] = np.fromstring(im.tobytes())\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def drawAllLetters(Y):\n",
    "    \"\"\"Draw numpy array interpreted as a letter per row and each row containing (angle, dist) pairs.\"\"\"\n",
    "    columns = 13\n",
    "    rows = math.ceil(Y.shape[0]/columns)\n",
    "    def drawPoints(im, points):\n",
    "        #temporary image to use to xor each part with main image\n",
    "        im2 = Image.new('1', size=(columns*cellsize, rows*cellsize), color=(0)) \n",
    "        draw = ImageDraw.Draw(im2) \n",
    "        draw.polygon(points, fill=1)\n",
    "        im = ImageChops.logical_xor(im, im2)\n",
    "        return im\n",
    "    scale = cellsize * 0.8\n",
    "    im = Image.new('1', size=(columns*cellsize, rows*cellsize), color=(0)) \n",
    "    for i in range(Y.shape[0]):\n",
    "        y,x = divmod(i, columns)\n",
    "        x *= cellsize\n",
    "        y = (y+1)*cellsize-1\n",
    "        points = []\n",
    "        for j in range(0, Y.shape[1], 2):\n",
    "            angle = Y[i][j]\n",
    "            dist = Y[i][j+1]\n",
    "            x2 = x+ abs(dist)*math.cos(angle*math.pi)*scale\n",
    "            y2 = y- abs(dist)*math.sin(angle*math.pi)*scale\n",
    "            if dist>0:\n",
    "                points += (x2,y2)\n",
    "            elif len(points)>2:\n",
    "                im = drawPoints(im, points)\n",
    "                points=[]\n",
    "            x=x2\n",
    "            y=y2\n",
    "    if len(points)>2:\n",
    "        im = drawPoints(im, points)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH0AQAAAADjreInAAAGKElEQVR4nO2cPY7cOBCFX7cHmMEG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\nf9Euvf7/F2varl69jm67/wBjoQGcD4wzTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=500x500 at 0x2C1DC5F17F0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('setup...')\n",
    "letters = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
    "letters += [chr(i) for i in range(ord('a'), ord('z')+1)]\n",
    "letters += ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "letters = ['A','B']\n",
    "np.set_printoptions(precision=2)\n",
    "ttx = ET.parse(r'deeper/BASKVILL.ttx') #read font data dumped from TrueType using fonttools\n",
    "#outputdim = readFont(ttx, letters)\n",
    "max_points_per_line = 10\n",
    "ygrid = np.linspace(0.0, 1.0, 100, endpoint=False) #y coordinates to render on\n",
    "X = np.identity(len(letters), dtype=float)  #input is 'one-hot' array, one per letter\n",
    "with tf.Session() as sess:\n",
    "    Y_true = generateTrueOutput(ttx, letters, max_points_per_line, ygrid)\n",
    "    #print(Y_true)\n",
    "    #drawAllLetters(Y)\n",
    "    #xxs = renderGlyph(tf.constant(Y[1]), max_points_per_line, ygrid)\n",
    "    im = drawGlyph(Y_true[1], ygrid)\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile model...\n",
      "fit the model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected renderGlyph to have shape (100, 30, 10) but got array with shape (2, 100, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-83b35e9f6a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit the model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1236\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1239\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1240\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected renderGlyph to have shape (100, 30, 10) but got array with shape (2, 100, 10)"
     ]
    }
   ],
   "source": [
    "def glyphDiffTF(y_true, y_pred):\n",
    "    return tf.reduce_max(renderGlyph(y_true, max_points_per_line, ygrid), axis=0)#-tf.reduce_min(glyph(y_pred, axis=1)) \n",
    "\n",
    "print('compile model...')\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(20, input_dim=X.shape[1]))\n",
    "#model.add(Dense(600, activation='relu'))\n",
    "#model.add(LSTM(4))#, return_sequences=True))\n",
    "model.add(layers.Dense(30, name='outlines'))\n",
    "model.add(layers.Lambda(lambda outline:renderGlyph(outline, max_points_per_line, ygrid), name='renderGlyph'))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print('fit the model...')\n",
    "model.fit(X, Y_true, epochs=500, batch_size=len(letters), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate the model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-5f9627eed323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate the model...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict outlines...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "print('evaluate the model...')\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "print('predict outlines...')\n",
    "outlines_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer('outlines').output)\n",
    "newY = outlines_model.predict(X, verbose=1)\n",
    "\n",
    "print(\"true vs pred:\")\n",
    "print(Y[0][:20])\n",
    "print(newY[0][:20])\n",
    "drawAllLetters(newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now, what happens when we predict mixed letters?\n",
    "newY = model.predict(np.random.random(X.shape), verbose=1)\n",
    "drawAllLetters(newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#what about interpolating between letters?  let's try gradually mixing A into B\n",
    "#need array [[1, 0, ...], [1, 0.1, ...]]\n",
    "A = X[0]\n",
    "B = X[1]\n",
    "steps=12\n",
    "mix = np.array([A*(steps-i)/steps + i*B/steps for i in range(steps+1)])\n",
    "#print(mix[:3])\n",
    "newY = model.predict(mix, verbose=1)\n",
    "drawAllLetters(newY)\n",
    "#not very convincing :(, perhaps raw points rather than angle, dist pairs for the outline would be better\n",
    "#also need to try interpolating A between two fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
